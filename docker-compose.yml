services:
  invokeai:
    image: 'ghcr.io/invoke-ai/invokeai:${IMAGE_TAG:-main-rocm}'
    extends:
      file: 'gpu-support.yml'
      service: '${GPU_DRIVER:-rocm}'
    ports:
      - '${BIND_ADDRESS:-127.0.0.1}:${BIND_PORT:-9090}:9090'
    volumes:
      - '${DATA_DIR:-./invokeai/data}:/invokeai:Z,U'
      - '${HF_CACHE_DIR:-./invokeai/cache/huggingface}:/invokeai/.cache/huggingface:Z,U'
      - '/etc/localtime:/etc/localtime:ro'
    env_file: '.env'
    restart: unless-stopped
    logging:
      driver: 'json-file'
      options:
        max-size: '${LOG_MAX_SIZE:-5m}'
        max-file: '${LOG_MAX_FILE:-5}'
  comfyui:
    build:
      context: ./comfyui/
      dockerfile: Containerfile.comfyui-rocm
    extends:
      file: 'gpu-support.yml'
      service: '${GPU_DRIVER:-rocm}'
    group_add:
      - video
    ports:
      - "8188:8188"
    volumes:
      - ./comfyui/data/models:/workspace/ComfyUI/models
      - ./comfyui/data/output:/workspace/ComfyUI/output
      - ./comfyui/data/input:/workspace/ComfyUI/input
      - ./comfyui/data/custom_nodes:/workspace/ComfyUI/custom_nodes
      - ./comfyui/data/user:/workspace/ComfyUI/user
    environment:
      - MODEL_DOWNLOAD=default
      - HIP_VISIBLE_DEVICES=0
      - CUDA_VISIBLE_DEVICES=""
    restart: unless-stopped
